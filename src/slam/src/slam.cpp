/*************************************************
 *  ???.cpp
 *  
 *  Uses error measurements from the pose estimate
 *  generated by pose_estimate.cpp to control the steering
 *  of the vehicle using a PID controller.
 *
 *  Subscribers: pose_estimate
 *  Publishers: N/A
 *
 *  Author: Zachary Kendrick
 ************************************************/

#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <sstream>
#include <iostream>
#include <cv_bridge/cv_bridge.h>
#include <opencv/cv.h>
#include <opencv/highgui.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/objdetect/objdetect.hpp>
#include <visualization_msgs/Marker.h>
#include <image_geometry/pinhole_camera_model.h>
#include <opencv2/features2d.hpp>
#include <opencv2/video/tracking.hpp>
#include <typeinfo>


using namespace cv;
using namespace std;
using namespace ros;

// ORB feature parameters
const static int N_FEATURES = 500;
const static float SCALE_FACTOR = 1.2f;
const static int N_LEVELS = 8;
const static int EDGE_THRESHOLD = 31;
const static int FIRST_LEVEL = 0;
const static int WTA_K = 2;
const static int SCORE_TYPE = ORB::HARRIS_SCORE;
const static int PATCH_SIZE = 31;
const static int FAST_THRESHOLD = 20;

// optical flow parameters																						
const static Size  WIN_SIZE = Size(21,21);
const static int MAX_LEVEL = 3;
const static TermCriteria TERM_CRIT = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01);
const static int FLAGS = 0;
const static double MIN_EIG_THRESHOLD = 1e-4;

// boolean for detecting new features
static bool new_detection = true;

// feature threshold
const static int FEATURE_THRESHOLD = 100;

// ORB feature detector
static Ptr<ORB> detector;

// previous points and frame
vector<Point2f> previous_points;
Mat previous_frame;

// find new features every n frames
static int num_frames = 5;

// optical flow mask
Mat flow_mask; 

// functions
void featureDetection(Mat frame, vector<Point2f>& previous_points, vector<KeyPoint>& keypoints);
bool featureTracking(Mat previous_frame, Mat current_frame, vector<Point2f>& previous_points, vector<Point2f>& current_points, vector<uchar>& status);
void getOpticalFlowMask(Mat flow_mask, vector<Point2f>& previous_points, vector<Point2f>& current_points, vector<Point2f>& found_points, vector<uchar>& status);



/*
   Function:
      Call back function that reads an image from the
      "raw_image" topic and finds lines using hough 
      transforms that make up the inner and outer
      markings of the lanes.
   Parameters:
      const sensor_msgs::ImageConstPtr& msg
   Publishes:
      Line list with id=2 (white lanes) and id=3 (yellow lanes)
*/

void imageLanePoints(const sensor_msgs::ImageConstPtr& msg)
{
  try
  {

    // current and previous frames
    Mat current_frame;

    // current and previous points
    vector<Point2f> current_points;
    vector<uchar> status;

    // find line segments that define lane markings
    Mat RGB_frame = cv_bridge::toCvShare(msg, "bgr8")->image;
    cvtColor(RGB_frame, current_frame, COLOR_RGB2GRAY);

    // detect new features or track old ones
    if (num_frames == 5 || new_detection) {

    	// new key points and optical flow mask
    	vector<KeyPoint> keypoints;
		flow_mask = Mat::zeros(current_frame.rows, current_frame.cols, CV_8UC3);

    	// detect features
    	featureDetection(current_frame, current_points, keypoints);
    	new_detection = false;
    	num_frames = 0;

    	// reset the points and frames
    	previous_frame = current_frame;
    	previous_points = current_points;

    	drawKeypoints(RGB_frame, keypoints, RGB_frame, Scalar(139,0,139));
    }
    else {

		vector<Point2f> found_points;
    	new_detection = featureTracking(previous_frame, current_frame, previous_points, current_points, status);
    	getOpticalFlowMask(flow_mask, previous_points, current_points, found_points, status);
    	num_frames++;
    }

    add(RGB_frame, flow_mask, RGB_frame);

    // display frames
    imshow("ORB Features", RGB_frame);
    waitKey(1);
  }
  catch (cv_bridge::Exception& e)
  {
    ROS_ERROR("Could not convert from '%s' to 'bgr8'.", msg->encoding.c_str());
  }
}



void getOpticalFlowMask(Mat flow_mask, vector<Point2f>& previous_points, vector<Point2f>& current_points, vector<Point2f>& found_points, vector<uchar>& status) {

	int rows = flow_mask.cols;
	int cols = flow_mask.rows;
	for(int i=0; i < status.size(); ++i) {
		if(status.at(i) && current_points.at(i).x >= 0 && current_points.at(i).y >= 0 && current_points.at(i).x < cols && current_points.at(i).y < rows) {
			line(flow_mask, previous_points.at(i), current_points.at(i), Scalar::all(255), 1);
			found_points.push_back(current_points.at(i));
		}
	}
	std::cout << "Found " << found_points.size() << " Keypoints " << endl;
	
	// set the previous points to the found points
	previous_points = found_points;

}




void featureDetection(Mat frame, vector<Point2f>& previous_points, vector<KeyPoint>& keypoints) {

	// get ORB key points
    detector->detect(frame, keypoints);
    std::cout << "Detected " << keypoints.size() << " Keypoints " << endl;
       
    // convert key points to points for optical flow
	KeyPoint::convert(keypoints, previous_points, vector<int>());
}




bool featureTracking(Mat previous_frame, Mat current_frame, vector<Point2f>& previous_points, vector<Point2f>& current_points, vector<uchar>& status) {

	// error message
	vector<float> err;

	// calculate optical flow
	calcOpticalFlowPyrLK(
	previous_frame,
	current_frame,
	previous_points,
	current_points,//found_points,
	status,
	err,
	WIN_SIZE,
	MAX_LEVEL,
	TERM_CRIT,
	FLAGS,
	MIN_EIG_THRESHOLD);

	// check that enough features were found
	return (current_points.size() < FEATURE_THRESHOLD); 

}



int main(int argc, char **argv)
{
  ros::init(argc, argv, "slam");
  ros::NodeHandle nh;
  cv::namedWindow("ORB Features");
  cv::startWindowThread();
  image_transport::ImageTransport it(nh);

  // ORB feature detector
	detector = ORB::create(
		N_FEATURES,
		SCALE_FACTOR,
		N_LEVELS,
		EDGE_THRESHOLD,
		FIRST_LEVEL,
		WTA_K,
		SCORE_TYPE,
		PATCH_SIZE,
		FAST_THRESHOLD);

  // subscribe to the "raw_image" topic
  image_transport::Subscriber sub = it.subscribe("raw_image", 1, imageLanePoints);

  // publish the "lane_lines"
  // lane_lines_pub = nh.advertise<visualization_msgs::Marker>("visualization_marker", 1);
  ros::Rate r(30);
  ros::spin();
  cv::destroyWindow("ORB Features");
}